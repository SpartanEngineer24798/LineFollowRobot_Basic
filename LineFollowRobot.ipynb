{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded Systems Final Project - Code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "from jetbot import Robot\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Region of interest (ROI) in the image. The ROI is defined by the variables roi_left, roi_top, roi_right, and roi_bottom.\n",
    "roi_left = 30\n",
    "roi_right = 194\n",
    "roi_top = 20\n",
    "roi_bottom = 194\n",
    "roi_mid = int((roi_right-roi_left)/2) # The roi_mid variable is the midpoint of the ROI, calculated as the average of roi_left and roi_right.\n",
    "\n",
    "# Range values (lower-upper) The variables TLow and THigh are the lower and upper range values for threshold operation.\n",
    "TLow = 0\n",
    "THigh = 50\n",
    "\n",
    "TShow = 0 # The TShow variable is a boolean that determines whether or not to show image \n",
    "\n",
    "TThreshold = 80\n",
    "\n",
    "# Error Tolerance\n",
    "Error_dev = 2\n",
    "\n",
    "# The nav_angle variable is a global variable that is used to store the navigation angle of a system. It is initially set to 0.\n",
    "global nav_angle\n",
    "nav_angle = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Black Line Detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLine(img, TShow, TLow, THigh):\n",
    "    default = img.copy()\n",
    "    cv2.line(default, (roi_left, roi_top), (roi_right, roi_top), (0, 0, 255), 1)\n",
    "    cv2.line(default, (roi_left, roi_bottom), (roi_right, roi_bottom), (0, 0, 255), 1)\n",
    "    cv2.line(default, (roi_mid, roi_top), (roi_mid, roi_bottom), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    img = img[roi_top:roi_bottom, roi_left:roi_right]\n",
    "    frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    frame = cv2.GaussianBlur(frame, (11,11), 0)\n",
    "    _, frame = cv2.threshold(frame, TThreshold, 255, cv2.THRESH_BINARY_INV)\n",
    "    frame = cv2.inRange(frame, TLow, THigh)\n",
    "    frame = cv2.erode(frame, None, iterations=3)\n",
    "    frame = cv2.dilate(frame, None, iterations=3)\n",
    "    frame = cv2.bitwise_not(frame)\n",
    "    \n",
    "    contours_blk, hierarchy_blk = cv2.findContours(frame, 1, cv2.CHAIN_APPROX_SIMPLE) \n",
    "# contours_blk variable is a list of contours detected in an image and the cv2.findContours function is used to find the contours in the image.\n",
    "# The cv2.findContours function returns two values: the first is a list of contours and the second is a hierarchy of contours. \n",
    "# The hierarchy is not used in this code, so it is stored in the hierarchy_blk variable. The contours_blk variable stores the list of contours.\n",
    "\n",
    "    if len(contours_blk) == 0:\n",
    "        cs = None\n",
    "\n",
    "    if len(contours_blk) > 0:\n",
    "        c = max(contours_blk, key=cv2.contourArea)\n",
    "        M = cv2.moments(c)\n",
    "        try:\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])+roi_top\n",
    "            error = cx - roi_mid\n",
    "        except:\n",
    "            cx = None\n",
    "            print(\"Error!\")\n",
    "        \n",
    "        if cx != None:\n",
    "            if TShow == 0:\n",
    "                cv2.drawContours(img, contours_blk, -1, (0, 255, 0), 1)\n",
    "                cv2.line(default, (cx, roi_top), (cx, roi_bottom), (255, 0, 0), 1)\n",
    "                cv2.line(default, (roi_left, cy), (roi_right, cy), (255, 0, 0), 1)\n",
    "        \n",
    "            cv2.circle(default, (cx, cy), 5, (0,255,0), 3)\n",
    "            cv2.line(default, (cx,cy), (roi_mid, cy), (0, 0, 255), 2)\n",
    "          \n",
    "    else:\n",
    "        cx = None\n",
    "\n",
    "\n",
    "# If there are any contours in the list, the code selects the contour with the largest area using the max function and a key function that returns the area of a contour. \n",
    "# The selected contour is stored in the c variable. The cv2.moments function is then used to calculate the moments of the selected contour. Moments are used to describe the shape of an object in an image. \n",
    "# The cv2.moments function returns a dictionary of moments calculated for the contour. The M variable stores this dictionary.\n",
    "# The code then calculates the centroid of the contour by dividing the m10 and m01 moments by the m00 moment. The centroid is the center of the contour and is represented by the cx and cy variables. The cx variable is the x-coordinate of the centroid, and the cy variable is the y-coordinate of the centroid.\n",
    "\n",
    "    return frame, img, default, cx\n",
    "\n",
    "# This function processes an image to detect a black line in it. The input to the function is an image img, a boolean TShow, and two integers TLow and THigh. The function first creates a copy of the image called default and draws two horizontal lines on it to mark the top and bottom boundaries of a ROI within the image and also draws a vertical line to mark the middle of the ROI. \n",
    "# The function then selects the ROI from the original image img by cropping it to the region between the top and bottom lines and between the left and right edges of the image.\n",
    "# The function then converts the cropped image to grayscale using the cv2.cvtColor function and applies Gaussian blur to it using the cv2.GaussianBlur function. It then applies binary thresholding to the blurred image using the cv2.threshold function, inverts the resulting binary image using the cv2.bitwise_not function, and applies erosion and dilation to it using the cv2.erode and cv2.dilate functions, respectively. \n",
    "# All of these are done to isolate and identify the black line in the image. The function then finds the contours of the resulting image using the cv2.findContours function.\n",
    "# Using that, if the function detects a black line in the image, it calculates the centroid of the contour and the error between the centroid and the middle of the ROI. It then draws the contour, the centroid, and the error on the images img and default. If the TShow input is set to True, the function also displays the original image with the black line contours drawn on it and the default image with the lines, centroid, and error drawn on it.\n",
    "# The function returns the binary image with the black line contours, the original image with the black line contours drawn on it, the default image , and the x-coordinate of the centroid. If no black line is detected, the function returns None for the x-coordinate of the centroid/center of intersection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Black Line Green Signal Detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLine_GSignal(img, TShow, TLow, THigh):\n",
    "    mode = \"center\"\n",
    "    GDetect = False\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    default = img.copy()\n",
    "    cv2.line(default, (roi_left, roi_top), (roi_right, roi_top), (0, 0, 255), 1)\n",
    "    cv2.line(default, (roi_left, roi_bottom), (roi_right, roi_bottom), (0, 0, 255), 1)\n",
    "    cv2.line(default, (roi_mid, roi_top), (roi_mid, roi_bottom), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    img = img[roi_top:roi_bottom, roi_left:roi_right]\n",
    "    \n",
    "    # Black Line Image Processing\n",
    "    frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    frame = cv2.GaussianBlur(frame, (11,11), 0)\n",
    "    _, frame = cv2.threshold(frame, TThreshold, 255, cv2.THRESH_BINARY_INV)\n",
    "    frame = cv2.inRange(frame, TLow, THigh)\n",
    "    frame = cv2.erode(frame, None, iterations=3)\n",
    "    frame = cv2.dilate(frame, None, iterations=3)\n",
    "    frame = cv2.bitwise_not(frame)\n",
    "    contours_blk, hierarchy_blk = cv2.findContours(frame, 1, cv2.CHAIN_APPROX_SIMPLE) #find contours with simple approximation similar to above\n",
    "    \n",
    "    # Green Signal Image Processing\n",
    "    GreenSignal = cv2.inRange(img, (0,65,0), (100,200,100))\n",
    "    GreenSignal = cv2.erode(GreenSignal, kernel,iterations=5)\n",
    "    GreenSignal = cv2.dilate(GreenSignal, kernel,iterations=9)\n",
    "    GreenSignal = cv2.bitwise_not(GreenSignal)\n",
    "    \n",
    "    contours_grn, hierarchy_grn = cv2.findContours(GreenSignal.copy(), cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE) #find contours with simple approximation similar to above\n",
    "\n",
    "# If there are any contours in the list, the code sets the GDetect variable to True and calculates the bounding rectangle of the first contour in the list using the cv2.boundingRect function. \n",
    "# The bounding rectangle is a rectangle that surrounds the contour and is represented by the x_grn, y_grn, w_grn, and h_grn variables. The x_grn and y_grn variables represent the top-left corner of the bounding rectangle, while the w_grn and h_grn variables represent the width and height of the bounding rectangle, respectively.\n",
    "\n",
    "# The code then calculates the center of the bounding rectangle by adding the x_grn and y_grn variables to half of the w_grn and h_grn variables, respectively. The center of the bounding rectangle is represented by the centerx_grn and centery_grn variables.\n",
    "# If the x_grn or y_grn or w_grn or h_grn variables are None, the code sets the GDetect variable to False.\n",
    "    \n",
    "    if len(contours_grn) > 0 :\n",
    "        GDetect = True\n",
    "        x_grn, y_grn , w_grn, h_grn = cv2.boundingRect(contours_grn[0])\n",
    "        if(x_grn is None or  y_grn is None or w_grn or h_grn is None):\n",
    "            GDetect = False\n",
    "        centerx_grn = x_grn + (w_grn/2)\n",
    "        centery_grn = y_grn + (h_grn/2)\n",
    "        \n",
    "       \n",
    "       # print(\"Green center y\", centery_grn)\n",
    "\n",
    "    if len(contours_blk) > 0:\n",
    "        c = max(contours_blk, key=cv2.contourArea)\n",
    "        M = cv2.moments(c)\n",
    "        try:\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])+roi_top\n",
    "            error = cx-roi_mid\n",
    "        except:\n",
    "            #cx = None\n",
    "            cx = roi_mid\n",
    "            cy = roi_mid\n",
    "            print(\"Error!\")\n",
    "\n",
    "    else:\n",
    "        cx = roi_mid\n",
    "        cy = roi_mid\n",
    "        \n",
    "    if GDetect: \n",
    "        deviation = abs(centerx_grn - cx)\n",
    "        if centerx_grn > cx and centery_grn > 150 and deviation<15 and deviation > 0:\n",
    "        #if centerx_grn > cx and centery_grn > 125:\n",
    "\n",
    "            mode = \"right\"\n",
    "            cx = centerx_grn + 100\n",
    "            #print(\"Turn right\")\n",
    "            # cv2.putText(img, \"Turn Right\", (100,100), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0),1)\n",
    "\n",
    "        elif centerx_grn < cx and centery_grn > 150 and deviation<15 and deviation > 0:\n",
    "        #elif centerx_grn <= cx and centery_grn > 125:\n",
    "            mode = \"left\"\n",
    "            #print(\"Turn left\")\n",
    "            cx = centerx_grn - 100\n",
    "            # cv2.putText(img, \"Turn Left\", (100,100), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0),1)\n",
    "            \n",
    "            \n",
    "    return frame, img, default, cx, mode\n",
    "\n",
    "\n",
    "\n",
    "#Explanation:\n",
    "# This function  processes an image from the robot's camera to detect the position of a black line and a green signal within a region of interest (ROI) in the image defined by the variables roi_left, roi_top, roi_right, and roi_bottom.\n",
    "#The function first creates a copy of the image called default and draws two horizontal lines on it to mark the top and bottom boundaries of a region of interest (ROI) within the image. It also draws a vertical line to mark the middle of the ROI. The function then selects the ROI from the original image img by cropping it to the region between the top and bottom red lines and between the left and right edges of the image.\n",
    "# The function then processes the image to detect the black line and the green signal. First, the image is converted to grayscale and then blurried using a Gaussian blur. The image is then thresholded using the cv2.threshold() function to create a binary image. The binary image is then eroded and dilated to reduce noise and make the contours of the objects in the image more distinct.\n",
    "# The function uses the cv2.findContours() function to find the contours of the black line and the green signal in the image. The contours of the black line are stored in the contours_blk variable, and the contours of the green signal are stored in the contours_grn variable.\n",
    "# The function then checks if the green signal was detected in the image by checking the length of the contours_grn list. If the green signal was detected, the function sets the GDetect flag to True and calculates the center position of the green signal using the x_grn, y_grn, w_grn, and h_grn variables, which are the bounding box coordinates of the green signal.\n",
    "# The function then checks if the black line was detected in the image by checking the length of the contours_blk list. If the black line was detected, the function calculates the center position of the black line using the moments of the largest contour in the contours_blk list. The center position is stored in the variables cx and cy.\n",
    "# Finally, the function determines the mode of the image based on the position of the black line and the green signal. If the green signal is detected and is to the right of the black line, the function sets the mode to \"right\". If the green signal is not detected, or if it is to the left of the black line, the function sets the mode to \"center\", and the function returns the binary image of the black line, the original image with the ROI marked, the default image with the ROI marked, the center position of the black line, and the mode of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Camera Output/View:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = Camera.instance()\n",
    "image_widget = widgets.Image()\n",
    "traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(image_widget)\n",
    "\n",
    "# Explanation:\n",
    "#\n",
    "# This code block uses the traitlets module to link the value attribute of a Camera object to the value attribute of an Image widget. The Camera object is used to capture images from a camera, and the Image widget is used to display the images.\n",
    "# The Camera.instance() function is used to create a singleton instance of the Camera class. We use this because a singleton allows only one instance of a class to be created. This is useful in situations where you want to ensure that there is only one object of a certain class that is shared among all users of that object such as that in this case of the camer and the image from it.\n",
    "# The bgr8_to_jpeg function is used to convert the value attribute of the Camera object, which is in the BGR8 format, to JPEG format before it is displayed in the Image widget. The display function is then used to show the Image widget.\n",
    "# When the code is run, the Image widget will display the images captured by the Camera object in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = camera.value.copy()\n",
    "frame, img, oryginal, cx, mode = BLine_GSignal(image, TShow, TLow, THigh)\n",
    "print(roi_mid, cx)\n",
    "\n",
    "print(mode)\n",
    "if(cx>=roi_mid + Error_dev):\n",
    "    print(\"Right!\")\n",
    "elif(cx<=roi_mid - Error_dev):\n",
    "    print(\"Left!\")\n",
    "else:\n",
    "    print(\"Center!\")\n",
    "\n",
    "#Explanation:\n",
    "# This code block captures an image from a camera using the Camera object, processes the image to detect a black line and a green signal in it using the BLine_GSignal function, and then checks the position of the black line relative to the center of the region of interest (ROI).\n",
    "# The BLine_GSignal function is called with the image, TShow, TLow, and THigh arguments and returns five values: frame, img, oryginal, cx, and mode. The frame and img variables are the binary images with the black line contours, the original variable is the original image with the black line contours drawn on it, the cx variable is the x-coordinate of the centroid of the black line, and the mode variable is a string indicating the mode of the system (e.g., \"center\", \"left\", \"right\").\n",
    "# The roi_mid variable is the midpoint of the ROI and is calculated as the average of roi_left and roi_right. The Error_dev variable is an error tolerance value.\n",
    "\n",
    "# After the image is processed, the code compares the value of cx to roi_mid with an error tolerance of Error_dev. If cx is greater than roi_mid + Error_dev, the code prints \"Right!\". If cx is less than roi_mid - Error_dev, the code prints \"Left!\". If cx is within the error tolerance range, the code prints \"Center!\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_gain_slider = widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value = 0.15, description='speed gain')\n",
    "steering_gain_slider = widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.30, description='steering gain')\n",
    "steering_dgain_slider = widgets.FloatSlider(min=0.0, max=0.5, step=0.001, value=0.15, description='steering kd')\n",
    "steering_bias_slider = widgets.FloatSlider(min=-0.3, max=0.3, step=0.01, value=0.0, description='steering bias')\n",
    "\n",
    "display(speed_gain_slider, steering_gain_slider, steering_dgain_slider, steering_bias_slider)\n",
    "\n",
    "# This code creates four sliders using the widgets module. \n",
    "# The first slider is a float slider with a minimum value of 0.0, a maximum value of 1.0, a step size of 0.01, and an initial value of 0.15.\n",
    "# The second slider is a float slider with a minimum value of 0.0, a maximum value of 1.0, a step size of 0.01, and an initial value of 0.30. \n",
    "# The third slider is a float slider with a minimum value of 0.0, a maximum value of 0.5, a step size of 0.001, and an initial value of 0.15.\n",
    "# The fourth slider is a float slider with a minimum value of -0.3, a maximum value of 0.3, a step size of 0.01, and an initial value of 0.0. \n",
    "# The display function is then used to show the sliders. These sliders can be used to adjust the values of four variables (the speed gain, steering gain, steering kd, and steering bias, respectively) in real-time by moving the sliders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Navigation Block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#PID and navigation resource #https://www.youtube.com/watch?v=4Y7zG48uHRo\n",
    "\n",
    "def Navigation(cx, roi_mid, nav_angle):\n",
    "    range_val = roi_left - roi_right\n",
    "    angle = (roi_mid - cx) / range_val\n",
    "    \n",
    "    #pid calculation\n",
    "    pid = angle * steering_gain_slider.value + (angle - nav_angle) * steering_dgain_slider.value\n",
    "    nav_angle = angle\n",
    "    \n",
    "    steering = pid + steering_bias_slider.value\n",
    "\n",
    "    \n",
    "    left =  max(min(speed_gain_slider.value + steering, 1.0), 0.0)\n",
    "    right = max(min(speed_gain_slider.value - steering, 1.0), 0.0)\n",
    "    # print(left,right)\n",
    "    # clear_output(wait = True)\n",
    "\n",
    "    robot.left_motor.value = max(min(speed_gain_slider.value + steering, 0.5), 0.0)\n",
    "    robot.right_motor.value = max(min(speed_gain_slider.value - steering, 0.5), 0.0)\n",
    "    \n",
    "#   Explanation:\n",
    "#\n",
    "#   The Navigation function is responsible for controlling the car's movement based on the input values of cx, roi_mid, and nav_angle. \n",
    "#   These values are used to calculate the angle of the car relative to the line being followed and the desired speed of the car.\n",
    "#   The function begins by calculating the range of values between roi_left and roi_right and storing the result in the variable range_val. \n",
    "#   It then calculates the angle of the car relative to the line being followed by dividing the difference between roi_mid and cx by range_val and storing the result in the variable angle.\n",
    "#   Next, the function calculates the pid value by multiplying angle by the value of the steering_gain_slider widget and adding the product of the difference between angle and nav_angle and the value of the steering_dgain_slider widget.\n",
    "#   The function then adds the value of the steering_bias_slider widget to the pid value and stores the result in the variable steering.\n",
    "#   Finally, the function uses the steering value and the speed_gain_slider value to calculate the speed of the left and right motors of the car. The calculated speeds are then clamped to the range between 0 and 0.5 and applied to the motors using the robot object. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution Block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cx_prev = 0\n",
    "TShow = False\n",
    "while True:\n",
    "    # print(mode)\n",
    "    image = camera.value.copy() #image from camera is copied to variable image\n",
    "    frame, img, default, cx, mode = BLine_GSignal(image, TShow, TLow, THigh)\n",
    "#setting steering and speed to 0 if no black line is detected\n",
    "    if(cx is None):\n",
    "        cx = roi_mid\n",
    "        steering_gain_slider*=0.0\n",
    "        speed_gain_slider*=0.0\n",
    "\n",
    "#setting steering and speed gain sliders as per mode\n",
    "    if(mode==\"right\" or mode==\"left\"):\n",
    "        steering_gain_slider.value*=2.0\n",
    "        speed_gain_slider.value*=1.5\n",
    "        for i in range(2500):\n",
    "            Navigation(cx, roi_mid,0)\n",
    "        steering_gain_slider.value/=2.0\n",
    "        speed_gain_slider.value/=1.5\n",
    "    else:\n",
    "        #if(abs(cx-roi_mid)>=50):\n",
    "            #cx = roi_mid                                                                                                                                                                                                   \n",
    "        Navigation(cx, roi_mid,0)\n",
    "   \n",
    "    # if TShow:\n",
    "    #     display(JupyterImage(img))\n",
    "    # else:\n",
    "    #     display(JupyterImage(frame))\n",
    "    # cx_prev = cx\n",
    "\n",
    "#   Explanation:\n",
    "#\n",
    "#   This code  block is responsible for calling the Navigation function with the appropriate arguments and using the BLines_GSignal function to get the values of cx and mode, resposinble for controlling the robot and start its movement on the track\n",
    "#   If the value of mode is \"right\" or \"left\", then the code multiplies the values of steering_gain_slider and speed_gain_slider by 2.0 and 1.5, respectively. It then calls the Navigation function 2500 times with the values of cx, roi_mid, and 0 as arguments. After the loop, it divides the values of steering_gain_slider and speed_gain_slider by 2.0 and 1.5, respectively.\n",
    "#   If the value of mode is not \"right\" or \"left\", then the code calls the Navigation function with the values of cx, roi_mid, and 0 as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# robot.left_motor.value = 0\n",
    "# robot.right_motor.value = 0\n",
    "robot.stop()\n",
    "\n",
    "camera.close()\n",
    "\n",
    "#  Explanation:\n",
    "#  This code block is responsible for stopping the robot and closing the camera object."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
